#defines connection info for proxy. comment out if not using a proxy server
#proxyhost=
#proxyport=80

#comma separated list of urls at which the crawler will start
starturls=http://www.healthspace.com/Clients/NewYork/Erie/Erie_Live_Web.nsf/Food-Search

#regex that urls MUST match to be included in crawl
includepatterns=.*www.healthspace.com/Clients/NewYork/Erie/.*

#regex of url patterns that will be ignored
ignorepatterns=.*.js,.*.css

#number of concurrent spider threads. 10 seems to be a good balance
#maxthreads=10
maxthreads=10

#how often the driver checks for completion and flushes output
sleepinterval=20000

groovyextractorclass=/Users/chris/development/healthinspections/scraper/src/main/java/org/cataractsoftware/healthinspections/scraper/DataExtractor.groovy
dataextractor=org.cataractsoftware.datasponge.extractor.GroovyExtractor

datawriter=org.cataractsoftware.healthinspections.scraper.MongoDataWriter
mongohost=localhost

